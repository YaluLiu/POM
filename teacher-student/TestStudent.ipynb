{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from studentnets import TinyNet\n",
    "import transforms as T\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import time\n",
    "import datetime\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "student network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TinyNet(device, 2).to(device)\n",
    "network = torch.load('student.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = []\n",
    "transforms.append(T.ToTensor())\n",
    "convert = T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-4df10fa41ab3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-4df10fa41ab3>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    img_tensor = torchvision.transforms.functional.to_tensor(image[0]).cuda()\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"cam1.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#image = Image.open(\"cam1.jpg\").convert(\"RGB\")\n",
    "\n",
    "img_tensor = torchvision.transforms.functional.to_tensor(image).cuda()\n",
    "img_tensor = img_tensor.to(device)\n",
    "img_tensor = img_tensor.reshape(1,3,720,1280)\n",
    "print(img_tensor.shape)\n",
    "print(type(img_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_network = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "teacher_network = teacher_network.to(device)\n",
    "teacher_network.eval()\n",
    "teacher_out = teacher_network(list(img_tensor.unbind(0)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_person = teacher_out[\"labels\"].cpu().detach().numpy() == 1\n",
    "cond_conf = teacher_out[\"scores\"].cpu().detach().numpy() > 0.9\n",
    "idx = cond_person & cond_conf\n",
    "B = teacher_out[\"masks\"][idx]\n",
    "image = None\n",
    "for img in B:\n",
    "    image = img if image is None else img+image\n",
    "    \n",
    "# for i in range(image.size()[1]):\n",
    "#     for j in range(image.size()[2]):\n",
    "#         if(image[0][i][j] > 1):\n",
    "#             image[0][i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_PIL(tensor):\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)\n",
    "    unloader = torchvision.transforms.ToPILImage(mode='L')\n",
    "    image = unloader(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 720, 1280])\n"
     ]
    }
   ],
   "source": [
    "print(type(teacher_out))\n",
    "print(type(image))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_PIL = tensor_to_PIL(image)\n",
    "np_data_1 = np.transpose(np.asarray(image_PIL))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_out = network.forward(img_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(student_out[0].cpu().detach().numpy()[0] > 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = student_out[0].cpu().detach().numpy()[0]\n",
    "np_data_2 = np.transpose(np.asarray(output)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 720)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np_data_2.shape)\n",
    "print(type(np_data_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n"
     ]
    }
   ],
   "source": [
    "print(np_data_1 == np_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(np_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.60158896 -0.51255167  0.4130808  ...  1.4430664   0.5077411\n",
      "   1.9455137 ]\n",
      " [ 0.86315906  1.0678021   2.5413334  ...  3.0615208   1.6656332\n",
      "   3.0518353 ]\n",
      " [ 0.9220699   1.4315592   3.1128485  ...  3.7646418   2.259517\n",
      "   3.8449736 ]\n",
      " ...\n",
      " [ 1.2712035   2.1755333   3.8095198  ...  1.7924509   1.253049\n",
      "   1.7671618 ]\n",
      " [ 1.1919205   1.6166079   3.051365   ...  1.291145    0.85464156\n",
      "   1.2911932 ]\n",
      " [ 0.6787516   1.7543154   2.5950363  ...  1.0364623   0.8011155\n",
      "   0.8184463 ]]\n"
     ]
    }
   ],
   "source": [
    "print(np_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp3d",
   "language": "python",
   "name": "vp3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
