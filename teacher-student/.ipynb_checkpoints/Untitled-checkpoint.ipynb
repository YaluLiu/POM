{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-99e7a593c569>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             optimizer = torch.optim.SGD(\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Examples:\n",
    "my_dataset = datasets.MNIST(root=\"./datasets/mnist\", train=True, download=True)\n",
    "validation_split = 0.1\n",
    "\n",
    "dataset_len = len(my_dataset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor(validation_split * dataset_len))\n",
    "validation_idx = np.random.choice(indices, size=val_len, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "\n",
    "# Contiguous split\n",
    "# train_idx, validation_idx = indices[split:], indices[:split]\n",
    "\n",
    "## Defining the samplers for each phase based on the random indices:\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(my_dataset, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(my_dataset, sampler=validation_sampler)\n",
    "data_loaders = {\"train\": train_loader, \"val\": validation_loader}\n",
    "data_lengths = {\"train\": len(train_idx), \"val\": val_len}\n",
    "\n",
    "# Training with Validation (your code + code from Pytorch tutorial: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
    "n_epochs = 40\n",
    "net = net.to_device()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            optimizer = torch.optim.SGD(\n",
    "                net.parameters(),\n",
    "                lr=0.01,\n",
    "                momentum=0.9,\n",
    "                weight_decay=1e-4)\n",
    "            net.train(True)  # Set model to training mode\n",
    "        else:\n",
    "            net.train(False)  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in data_loaders[phase]:\n",
    "\n",
    "            # get the input images and their corresponding labels\n",
    "            images = data['image']\n",
    "            key_pts = data['keypoints']\n",
    "\n",
    "            # flatten pts\n",
    "            key_pts = key_pts.view(key_pts.size(0), -1)\n",
    "\n",
    "            # wrap them in a torch Variable\n",
    "            images, key_pts = Variable(images), Variable(key_pts)\n",
    "\n",
    "            # convert variables to floats for regression loss\n",
    "            key_pts = key_pts.type(torch.FloatTensor)\n",
    "            images = images.type(torch.FloatTensor)\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            output_pts = net(images)\n",
    "\n",
    "            # calculate the loss between predicted and target keypoints\n",
    "            loss = criterion(output_pts, key_pts)\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                # update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            running_loss += loss.data[0]\n",
    "\n",
    "        epoch_loss = running_loss / data_lengths[phase]\n",
    "        print('{} Loss: {:.4f}'.format(phase, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp3d",
   "language": "python",
   "name": "vp3d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
