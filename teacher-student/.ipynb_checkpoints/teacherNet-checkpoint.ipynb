{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from studentnets import TinyNet\n",
    "import transforms as T\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "import time\n",
    "import datetime\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "teacher network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_network = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "teacher_network = teacher_network.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "student network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_network = TinyNet(device, 2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = \"/media/yalu/6066C1DD66C1B3D6/images/cam{}\"\n",
    "cams_num = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class teacherDataset(object):\n",
    "    def __init__(self, root, cams_num, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.imgs = []\n",
    "        for cam_id in range(cams_num):\n",
    "            img_root = self.root.format(cam_id)\n",
    "            img_names = sorted(os.listdir(img_root))\n",
    "            self.imgs += [os.path.join(img_root, img_name) for img_name in img_names]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = self.imgs[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img.convert(\"RGB\"))\n",
    "        target = {}\n",
    "        if self.transforms is not None:\n",
    "            img, _ = self.transforms(img, target)\n",
    "#             try:\n",
    "#                 img.verify()\n",
    "#                 img = np.array(img.convert(\"RGB\"))\n",
    "#                 target = {}\n",
    "#                 if self.transforms is not None:\n",
    "#                     img, _ = self.transforms(img, target)\n",
    "#                 break\n",
    "#             except Exception:\n",
    "#                 print('Invalid image on {}'.format(img_path))\n",
    "#                 idx = 0\n",
    "#                 continue\n",
    "            \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genMask(output, score_th = 0.9, mask_th = 0.2, CUDA = True):\n",
    "    scores = output[\"scores\"]\n",
    "    masks = output[\"masks\"]\n",
    "    labels = output[\"labels\"]\n",
    "    mask_out = torch.sum(masks[(scores > score_th) & (labels == 1)], 0)\n",
    "    mask_out = torch.squeeze(mask_out > mask_th)\n",
    "    return mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(input, target):\n",
    "    loss = nn.functional.cross_entropy(input, target, ignore_index=255)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset = teacherDataset(img_paths, cams_num, get_transform(train=False))\n",
    "\n",
    "validation_split = 0.1\n",
    "\n",
    "dataset_len = len(my_dataset)\n",
    "indices = list(range(dataset_len))\n",
    "\n",
    "# Randomly splitting indices:\n",
    "val_len = int(np.floor(validation_split * dataset_len))\n",
    "validation_idx = np.random.choice(indices, size=val_len, replace=False)\n",
    "train_idx = list(set(indices) - set(validation_idx))\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "validation_sampler = SubsetRandomSampler(validation_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(my_dataset, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(my_dataset, sampler=validation_sampler)\n",
    "data_loaders = {\"train\": train_loader, \"val\": validation_loader}\n",
    "data_lengths = {\"train\": len(train_idx), \"val\": val_len}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(\n",
    "    student_network.parameters(),\n",
    "    lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4)\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer,\n",
    "    lambda x: (1 - x / (len(train_idx) * 100)) ** 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# teacher_network.eval()\n",
    "\n",
    "# for i in range(3):\n",
    "#     for epoch in range(1, epochs):\n",
    "#         tDataset = teacherDataset(data_root, epoch, get_transform(train=False))\n",
    "#         data_loader_teacher = torch.utils.data.DataLoader(\n",
    "#                 tDataset, batch_size=b_size, shuffle=True, num_workers=4,\n",
    "#                 collate_fn=utils.collate_fn)\n",
    "#         print(\"epoch -- \", epoch)\n",
    "#         step_loss = []\n",
    "#         start_time = time.time()\n",
    "#         for image, target in data_loader_teacher:\n",
    "#             image = image.to(device)\n",
    "#             outputs = teacher_network(list(image.unbind(0)))\n",
    "\n",
    "#             # generate teacher output as student target\n",
    "#             T_seg = [genMask(output) for output in outputs]\n",
    "#             T_seg = torch.stack(T_seg).long()\n",
    "\n",
    "#             # student network infer\n",
    "#             student_out = student_network.forward(image)\n",
    "\n",
    "\n",
    "#             # train student network\n",
    "#             loss = criterion(student_out, T_seg)\n",
    "#             step_loss.append(loss.item())\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "\n",
    "#         print(\"step loss : \", np.mean(step_loss))\n",
    "#         total_time = time.time() - start_time\n",
    "#         total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "#         print('time cost : {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "***************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************train Loss: 0.1273\n",
      "***********************************************************************************************val Loss: 0.0595\n",
      "Epoch 1/1\n",
      "----------\n",
      "***************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************train Loss: 0.0492\n",
      "************"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "\n",
    "\n",
    "teacher_network.eval()\n",
    "for epoch in range(n_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            student_network.train(True)  # Set model to training mode\n",
    "        else:\n",
    "            student_network.train(False)  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        step_loss = []\n",
    "        # Iterate over data.\n",
    "        for image, target in data_loaders[phase]:\n",
    "            image = image.to(device)\n",
    "            outputs = teacher_network(list(image.unbind(0)))\n",
    "\n",
    "            # generate teacher output as student target\n",
    "            T_seg = [genMask(output) for output in outputs]\n",
    "            T_seg = torch.stack(T_seg).long()\n",
    "\n",
    "            # student network infer\n",
    "            student_out = student_network.forward(image)\n",
    "            loss = criterion(student_out, T_seg)\n",
    "            \n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # backward + optimize only if in training phase\n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            running_loss += loss.item()\n",
    "            print(\"*\", end = \"\")\n",
    "\n",
    "        epoch_loss = running_loss / data_lengths[phase]\n",
    "        print('{} Loss: {:.4f}'.format(phase, epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get tensor from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = Image.open(\"cam1.jpg\").convert(\"RGB\")\n",
    "image = cv2.imread(\"cam1.jpg\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "print(image.shape)\n",
    "\n",
    "img_tensor = torchvision.transforms.functional.to_tensor(image).cuda()\n",
    "img_tensor = img_tensor.to(device)\n",
    "img_tensor = img_tensor.reshape(1,3,720,1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_infer_start_time = time.time()\n",
    "teacher_out = teacher_network(list(img_tensor.unbind(0)))\n",
    "teacher_infer_time = time.time() - teacher_infer_start_time\n",
    "teacher_infer_time_str = str(datetime.timedelta(milliseconds=teacher_infer_time/1))\n",
    "print('teacher infer time cost : {} '.format(teacher_infer_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate teacher output as student target\n",
    "T_seg = [genMask(output) for output in teacher_out]\n",
    "T_seg = torch.stack(T_seg).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_infer_start_time = time.time()\n",
    "student_out = student_network.forward(img_tensor)\n",
    "student_infer_time = time.time() - student_infer_start_time\n",
    "student_infer_time_str = str(datetime.timedelta(milliseconds=student_infer_time/1))\n",
    "print('student infer time cost : {}'.format(student_infer_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.transforms.ToPILImage()(img_tensor[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(T_seg[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(student_out[0].cpu().detach().numpy()[0] < 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,'student.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
